{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import cred\n",
    "import glob\n",
    "\n",
    "# Set up Spotify credentials (to access API)\n",
    "# cred.py is a separate file with the registered app id, secret, and redirect url (private file)\n",
    "client_credentials_manager = SpotifyClientCredentials(cred.client_id, cred.client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Locate directory with original files\n",
    "json_dir_name = '/Volumes/MUSIC/spotify_million_playlist_dataset/data'\n",
    "\n",
    "# Import all data files with the .json extension\n",
    "json_pattern = os.path.join(json_dir_name, '*.json')\n",
    "json_files = glob.glob(json_pattern)\n",
    "json_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_uris = []\n",
    "\n",
    "# For each JSON file in the data folder, loop through each playlist in the file\n",
    "# For each playist in the file, loop through each track in that playlsit\n",
    "# For each track in that playlist, extract the track URI and add it to the global list\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(json_dir_name, js), encoding='utf-8') as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        \n",
    "        for j in range(len(json_text[\"playlists\"])):\n",
    "          for k in range(len(json_text[\"playlists\"][j][\"tracks\"])):\n",
    "            \n",
    "            track_uri = json_text[\"playlists\"][j][\"tracks\"][k]['track_uri']\n",
    "            track_uris.append(track_uri)\n",
    "            \n",
    "        if (index + 1) % 50 == 0:\n",
    "          print(f'I am on file {index + 1}')\n",
    "\n",
    "# Remove duplicates, keeping order (in case restarting is needed)\n",
    "list_uris = list(dict.fromkeys(track_uris))\n",
    "\n",
    "# 25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500 \n",
    "  \n",
    "# Break list of URIs into chunks of n = 500 using list comprehension\n",
    "chunks = [list_uris[i * n:(i + 1) * n] for i in range((len(list_uris) + n - 1) // n )] \n",
    "\n",
    "#20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_tracks(seed_tracks):\n",
    "  '''\n",
    "  Takes a list of track URIs and gives, for each track, all of the tracks on the album\n",
    "  '''\n",
    "  print('Starting to get album tracks.')\n",
    "  song_uris = []\n",
    "\n",
    "  for i in range(len(seed_tracks)):\n",
    "    # Error catching; program will fail without an internet connection\n",
    "    try:\n",
    "      track_info = sp.track(seed_tracks[i])\n",
    "    except:\n",
    "      continue\n",
    "    album_uri = track_info['album']['uri']\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "      try:\n",
    "        album_info = sp.album_tracks(album_uri, offset=offset)\n",
    "      except:\n",
    "        break\n",
    "      if len(album_info['items']) == 0:\n",
    "          break\n",
    "      for j in range(len(album_info['items'])):\n",
    "          if album_info['items'][j] == None:\n",
    "              continue\n",
    "          else:\n",
    "              song_uris.append(album_info['items'][j]['uri'])  \n",
    "      offset = offset + len(album_info['items'])\n",
    "      time.sleep(0.001)\n",
    "\n",
    "    if i == 249:\n",
    "      print(f'I am on song 250 out of {len(seed_tracks)}')\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "  # Removes duplicates (does not keep order, but all of the songs in the final list will be the same as long \n",
    "  # as the chunks remain in the same order)\n",
    "  return list(set(song_uris))\n",
    "\n",
    "def get_track_features(song_uris):\n",
    "  '''\n",
    "  Gets track info and track audio features when given a list of song URIs\n",
    "  '''\n",
    "  print('Starting to get track features.')\n",
    "  print(f'There are {len(song_uris)} to analyze.')\n",
    "\n",
    "  # Create empty data frame to append to\n",
    "  dframe = pd.DataFrame(columns=['album_uri', 'artist_uri', 'artist_name', 'album_name', 'release_date', 'disc_number', 'popularity','track_number', 'duration', 'explicit', 'track_name', 'track_uri', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'intstrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'])\n",
    "  \n",
    "  # For each song in the inputted list of URIs, grab the song's info and features\n",
    "  # Create a dictionary of the information and append that info to the dataframe created above\n",
    "  # Returns completed dataframe of info for all songs in the inputted list\n",
    "  for i in range(len(song_uris)):\n",
    "    \n",
    "    # Will fail without an internet connection\n",
    "    try:\n",
    "      track_info = sp.track(song_uris[i])\n",
    "    \n",
    "      album_uri = track_info['album']['uri']\n",
    "      artist_uri = track_info['artists'][0]['uri']\n",
    "      artist_name = track_info['artists'][0]['name']\n",
    "      album_name = track_info['album']['name']\n",
    "      release_date = track_info['album']['release_date']\n",
    "      disc_number = track_info['disc_number']\n",
    "      popularity = track_info['popularity']\n",
    "      track_number = track_info['track_number']\n",
    "      duration = track_info['duration_ms']\n",
    "      explicit = track_info['explicit']\n",
    "      track_name = track_info['name']\n",
    "      track_uri = track_info['uri']\n",
    "      time.sleep(0.001)\n",
    "    except:\n",
    "      continue\n",
    "\n",
    "    try:\n",
    "      track_features = sp.audio_features(song_uris[i])\n",
    "      \n",
    "      danceability = track_features[0]['danceability']\n",
    "      energy = track_features[0]['energy']\n",
    "      key = track_features[0]['key']\n",
    "      loudness = track_features[0]['loudness']\n",
    "      mode = track_features[0]['mode']\n",
    "      speechiness = track_features[0]['speechiness']\n",
    "      acousticness = track_features[0]['acousticness']\n",
    "      instrumentalness = track_features[0]['instrumentalness']\n",
    "      liveness = track_features[0]['liveness']\n",
    "      valence = track_features[0]['valence']\n",
    "      tempo = track_features[0]['tempo']\n",
    "      time_signature = track_features[0]['time_signature']\n",
    "      time.sleep(0.001)\n",
    "    except:\n",
    "      continue\n",
    "    \n",
    "    observation = {\n",
    "      'album_uri': album_uri,\n",
    "      'artist_uri': artist_uri,\n",
    "      'artist_name': artist_name,\n",
    "      'album_name': album_name,\n",
    "      'release_date': release_date,\n",
    "      'disc_number': disc_number,\n",
    "      'popularity': popularity,\n",
    "      'track_number': track_number,\n",
    "      'duration': duration,\n",
    "      'explicit': explicit,\n",
    "      'track_name': track_name,\n",
    "      'track_uri': track_uri,\n",
    "      'danceability': danceability,\n",
    "      'energy': energy,\n",
    "      'key': key,\n",
    "      'loudness': loudness,\n",
    "      'mode': mode,\n",
    "      'speechiness': speechiness,\n",
    "      'acousticness': acousticness,\n",
    "      'instrumentalness': instrumentalness,\n",
    "      'liveness': liveness,\n",
    "      'valence': valence,\n",
    "      'tempo': tempo,\n",
    "      'time_signature': time_signature\n",
    "    }\n",
    "    \n",
    "    dframe = dframe.append(pd.DataFrame([observation]))\n",
    "    if (i + 1) % 2000 == 0:\n",
    "      print(f'Currently on song {i + 1} out of {len(song_uris)}')\n",
    "  return dframe\n",
    "\n",
    "\n",
    "def make_df(index):\n",
    "  '''\n",
    "  Uses chunks to get all album tracks for each song in the chunk and all track features for each song on\n",
    "  the albums. Keeps track of how long each chunk takes.\n",
    "  '''\n",
    "  print(f'Starting chunk {index + 1}')\n",
    "  t_1 = time.time()\n",
    "  chunk_uris = get_album_tracks(chunks[index])\n",
    "  chunk_df = get_track_features(chunk_uris)\n",
    "  t_2 = time.time()\n",
    "  print(f'Completing chunk {index + 1} took {round((t_2 - t_1)/60, 2)} minutes.')\n",
    "  return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe for final output\n",
    "df = pd.DataFrame(columns=['album_uri', 'artist_uri', 'artist_name', 'album_name', 'release_date', 'disc_number', 'popularity','track_number', 'duration', 'explicit', 'track_name', 'track_uri', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'intstrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chunk 1422\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 5093 to analyze.\n",
      "Currently on song 2000 out of 5093\n",
      "Currently on song 4000 out of 5093\n",
      "Completing chunk 1422 took 20.71 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (5093, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (5093, 25)\n",
      "Starting chunk 1423\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4514 to analyze.\n",
      "Currently on song 2000 out of 4514\n",
      "Currently on song 4000 out of 4514\n",
      "Completing chunk 1423 took 17.63 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (9607, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (9573, 25)\n",
      "Starting chunk 1424\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4354 to analyze.\n",
      "Currently on song 2000 out of 4354\n",
      "Currently on song 4000 out of 4354\n",
      "Completing chunk 1424 took 17.02 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (13927, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (13877, 25)\n",
      "Starting chunk 1425\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 5265 to analyze.\n",
      "Currently on song 2000 out of 5265\n",
      "Currently on song 4000 out of 5265\n",
      "Completing chunk 1425 took 19.94 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (19142, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (19100, 25)\n",
      "Starting chunk 1426\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4455 to analyze.\n",
      "Currently on song 2000 out of 4455\n",
      "Currently on song 4000 out of 4455\n",
      "Completing chunk 1426 took 17.24 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (23555, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (23516, 25)\n",
      "Starting chunk 1427\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4507 to analyze.\n",
      "Currently on song 2000 out of 4507\n",
      "Currently on song 4000 out of 4507\n",
      "Completing chunk 1427 took 17.44 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (28023, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (28013, 25)\n",
      "Starting chunk 1428\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/tracks/3JJL4OmS8VmYqTODuIlKbq with Params: {'market': None} returned 404 due to non existing id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get track features.\n",
      "There are 3843 to analyze.\n",
      "Currently on song 2000 out of 3843\n",
      "Completing chunk 1428 took 15.22 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (31856, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (31805, 25)\n",
      "Starting chunk 1429\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 5704 to analyze.\n",
      "Currently on song 2000 out of 5704\n",
      "Currently on song 4000 out of 5704\n",
      "Completing chunk 1429 took 21.5 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (37508, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (37453, 25)\n",
      "Starting chunk 1430\n",
      "Starting to get album tracks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/tracks/6CNzVurjdLR4seIfAsRxai with Params: {'market': None} returned 404 due to non existing id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4077 to analyze.\n",
      "Currently on song 2000 out of 4077\n",
      "Currently on song 4000 out of 4077\n",
      "Completing chunk 1430 took 16.31 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (41530, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (41460, 25)\n",
      "Starting chunk 1431\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4524 to analyze.\n",
      "Currently on song 2000 out of 4524\n",
      "Currently on song 4000 out of 4524\n",
      "Completing chunk 1431 took 17.53 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (45983, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (45968, 25)\n",
      "Starting chunk 1432\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4533 to analyze.\n",
      "Currently on song 2000 out of 4533\n",
      "Currently on song 4000 out of 4533\n",
      "Completing chunk 1432 took 17.59 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (50501, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (50440, 25)\n",
      "Starting chunk 1433\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/tracks/37TWuMW8fj2p9mfjNAQhP5 with Params: {'market': None} returned 404 due to non existing id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get track features.\n",
      "There are 4116 to analyze.\n",
      "Currently on song 2000 out of 4116\n",
      "Currently on song 4000 out of 4116\n",
      "Completing chunk 1433 took 16.24 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (54556, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (54434, 25)\n",
      "Starting chunk 1434\n",
      "Starting to get album tracks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/tracks/0soGt31beG9D6zsDjA75Vy with Params: {'market': None} returned 404 due to non existing id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get track features.\n",
      "There are 5363 to analyze.\n",
      "Currently on song 2000 out of 5363\n",
      "Currently on song 4000 out of 5363\n",
      "Completing chunk 1434 took 20.35 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (59797, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (59749, 25)\n",
      "Starting chunk 1435\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4946 to analyze.\n",
      "Currently on song 2000 out of 4946\n",
      "Currently on song 4000 out of 4946\n",
      "Completing chunk 1435 took 19.28 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (64693, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (64514, 25)\n",
      "Starting chunk 1436\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 5300 to analyze.\n",
      "Currently on song 2000 out of 5300\n",
      "Currently on song 4000 out of 5300\n",
      "Completing chunk 1436 took 20.53 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (69813, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (69728, 25)\n",
      "Starting chunk 1437\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 3806 to analyze.\n",
      "Currently on song 2000 out of 3806\n",
      "Completing chunk 1437 took 15.17 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (73534, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (73455, 25)\n",
      "Starting chunk 1438\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4060 to analyze.\n",
      "Currently on song 2000 out of 4060\n",
      "Currently on song 4000 out of 4060\n",
      "Completing chunk 1438 took 15.99 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (77515, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (77382, 25)\n",
      "Starting chunk 1439\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/tracks/6SctaFY2Rgb3R50I7tiWlK with Params: {'market': None} returned 404 due to non existing id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to get track features.\n",
      "There are 4099 to analyze.\n",
      "Currently on song 2000 out of 4099\n",
      "Currently on song 4000 out of 4099\n",
      "Completing chunk 1439 took 16.3 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (81481, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (81330, 25)\n",
      "Starting chunk 1440\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4511 to analyze.\n",
      "Currently on song 2000 out of 4511\n",
      "Currently on song 4000 out of 4511\n",
      "Completing chunk 1440 took 17.52 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (85841, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (85729, 25)\n",
      "Starting chunk 1441\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4516 to analyze.\n",
      "Currently on song 2000 out of 4516\n",
      "Currently on song 4000 out of 4516\n",
      "Completing chunk 1441 took 17.48 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (90244, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (90089, 25)\n",
      "Starting chunk 1442\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4616 to analyze.\n",
      "Currently on song 2000 out of 4616\n",
      "Currently on song 4000 out of 4616\n",
      "Completing chunk 1442 took 17.96 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (94702, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (94627, 25)\n",
      "Starting chunk 1443\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 5219 to analyze.\n",
      "Currently on song 2000 out of 5219\n",
      "Currently on song 4000 out of 5219\n",
      "Completing chunk 1443 took 19.86 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (99846, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (99737, 25)\n",
      "Starting chunk 1444\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 3805 to analyze.\n",
      "Currently on song 2000 out of 3805\n",
      "Completing chunk 1444 took 15.16 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (103542, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (103439, 25)\n",
      "Starting chunk 1445\n",
      "Starting to get album tracks.\n",
      "I am on song 250 out of 500\n",
      "Starting to get track features.\n",
      "There are 4811 to analyze.\n",
      "Currently on song 2000 out of 4811\n",
      "Currently on song 4000 out of 4811\n",
      "Completing chunk 1445 took 18.49 minutes.\n",
      "The dimensions of the data frame before droppping duplicates are (108250, 25)\n",
      "The dimensions of the data frame after droppping duplicates are (108204, 25)\n"
     ]
    }
   ],
   "source": [
    "# len(chunks) = 4525\n",
    "\n",
    "# With inputted indices, loops through chunks and supplies each chunk to the functions above, printing \n",
    "# the dimensions\n",
    "# Try to stay below 140,000 rows for file size concerns\n",
    "indices = [i for i in range(1421, 1445)]\n",
    "\n",
    "for index in indices:\n",
    "  dfpiece = make_df(index)\n",
    "  df = df.append(dfpiece)\n",
    "  print(f'The dimensions of the data frame before droppping duplicates are {df.shape}')\n",
    "  df = df.drop_duplicates(subset = \"track_uri\")\n",
    "  print(f'The dimensions of the data frame after droppping duplicates are {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to disk at the file path\n",
    "df.to_csv(path_or_buf=r'/Users/iancurtis/Documents/coding/musicanalysis/original_data/chunks1401-1421.csv', index = False, index_label = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
